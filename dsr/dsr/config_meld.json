{
   "task": {
      "task_type" : "regression",
      "name" : "Nguyen-1",
      "function_set" : null,
      "dataset" : {
         "benchmark_source": "benchmarks.csv",
         "name" : null,
         "noise": null,
         "root" : null,
         "backup" : false
      },
      "metric" : "inv_nrmse",
      "metric_params" : [1.0],
      "extra_metric_test" : null,
      "extra_metric_test_params" : [1.0],
      "threshold" : 1e-12,
      "protected" : false,
      "reward_noise" : 0.0,
      "reward_noise_type" : "r",
      "normalize_variance" : false
   },
   "prior": {
      "length" : {"min_" : 4, "max_" : 30},
      "repeat" : {"tokens" : "const", "max_" : 3},
      "inverse" : {},
      "const" : {},
      "trig" : {}
   },
   "training": {
      "logdir": "./log",
      "n_epochs": null,
      "n_samples": 2000000,
      "batch_size": 500,
      "complexity": "length",
      "complexity_weight": 0.0,
      "const_optimizer": "scipy",
      "const_params": {},
      "alpha": 0.5,
      "epsilon": 0.1,
      "verbose": true,
      "baseline": "R_e",
      "b_jumpstart": false,
      "n_cores_batch": 1,
      "summary": true,
      "debug": 0,
      "output_file": null,
      "save_all_r": false,
      "early_stopping": true,
      "hof": 100,
      "eval_all": false,
      "pareto_front": false
   },
   "controller": {
      "cell": "lstm",
      "num_layers": 1,
      "num_units": 32,
      "initializer": "zeros",
      "embedding": false,
      "embedding_size": 8,
      "optimizer": "adam",
      "learning_rate": 0.001,
      "observe_action": false,
      "observe_parent": true,
      "observe_sibling": true,
      "use_old_entropy": false,
      "entropy_weight": 0.005,
      "ppo": false,
      "ppo_clip_ratio": 0.2,
      "ppo_n_iters": 10,
      "ppo_n_mb": 4,
      "pqt": false,
      "pqt_k": 10,
      "pqt_batch_size": 1,
      "pqt_weight": 200.0,
      "pqt_use_pg": false,
      "max_length": 30
   },
   "gp_meld": {
   		"desc_run_gp_meld" 		  	: "Turn on the GP component to iterate with RL?",
   		"run_gp_meld"             	: true,
   		"desc_init_population_size"	: "Random population to start out with other than what we get from the controller. Setting to 1 smooths init (this is a small bug). Default: 1",
        "init_population_size"    	: 1,
        "desc_p_crossover"		  	: "Probability that GP will cross bread two memebers. Note, this can co-occure independantly with mutate. Default: 0.5",
        "p_crossover"             	: 0.5,    
        "desc_p_mutate"			  	: "Probability that a member will be mutated. Note, this can co-occure independantly with crossover. Default: 0.5",
        "p_mutate"                	: 0.5,    
        "desc_seed"					: "Random seed into GP.",  
        "seed"                    	: 0,        
        "desc_verbose"			  	: "Verbosity for GP components.",
        "verbose"                 	: false,      
        "desc_max_len"			  	: "This is the max lenght of a string in GP. Most of the time, this should be the same as for RL. Default: 30",
        "max_len"                 	: 30,     
        "desc_min_len"			  	: "This is the min lenght of a string in GP. Most of the time, this should be the same as for RL. Default: 4",
        "min_len"                 	: 4,     
        "desc_steps"			  	: "How many times we run GP between each call to RL. A good numbers seemd to be from 5 to 20. Default: 20",    
        "steps"                	  	: 20,        
        "desc_rand_pop_n"		  	: "Before we run GP steps times, inject this many completely random individuals. Default: 0",
        "rand_pop_n"              	: 0,
        "desc_pop_pad"        		: "We can add actions more than once exanding GP population x many times. 0 turns this off. Default: 0",
        "pop_pad"                 	: 0,         
        "desc_fitness_metric"		: "For GP, nmse or nrmse",
        "fitness_metric"          	: "nmse",    
        "desc_recycle_max_size"  	: "If not zero, we hold over GP population from prior epochs. 1500 works well if we want to do this. Default: 0",
        "recycle_max_size"        	: 0,        
        "desc_tournament_size"		: "A larger number can converge faster, but me be more biased? Default: 3",
        "tournament_size"         	: 5,   
        "desc_max_depth"       		: "This is mainly a widget to control memory usage. Python sets a hard limit of 90. Default: 17",
        "max_depth"               	: 30,     
        "desc_train_n"    			: "How many GP observations to return with RL observations. These still get trimmed if scores are poor later on. 0 turns off return.",
        "train_n"                 	: 10,    
        "desc_mutate_tree_max" 		: "How deep can an inserted mutation tree be? Deeper swings more wildly. 5 is kind of crazy. Turn up with frustration?, Default: 2",
        "mutate_tree_max"         	: 3,        
        "max_const"               	: 3,
        "constrain_const"         	: true
   },
   "language_model_prior": {
        "saved_language_model_path": "./language_model/model/saved_model",
        "saved_language_model_lib" : "./language_model/model/saved_model/word_dict.pkl",
        "embedding_size":32, 
        "num_layers":1, 
        "num_hidden":256,
        "prob_sharing": true
    }
}
