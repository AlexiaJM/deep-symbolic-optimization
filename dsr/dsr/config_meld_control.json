{
   "task": {
      "task_type" : "control",
      "name": "Pendulum-v0",
      "action_spec" : [null],
      "n_episodes_slice" : 5,
      "n_episodes_train" : 25,
      "n_episodes_validate" : 50,
      "n_episodes_long_validate" : 1000,
      "n_episodes_test" : 1000,
      "success_score": 0.0,
      "function_set" : ["add", "sub", "mul", "div", "sin", "cos", "exp", "log", 0.1, 1, 5],
      "stochastic" : true,
      "protected" : false,
      "fix_seeds" : false,
      "episode_seed_shift" : 0,
      "env_kwargs" : null,
      "do_validate" : true,
      "do_long_validate" : true,
      "long_validation_finalists" : 5,
      "slice_optimize_stat" : "mean"
   },
   "prior": {
      "length" : {"min_" : 4, "max_" : 30},
      "repeat" : {"tokens" : "const", "max_" : 3},
      "inverse" : {},
      "const" : {},
      "trig" : {}
   },
   "training": {
      "logdir": "./log",
      "n_epochs": null,
      "n_samples": 2000000,
      "batch_size": 1000,
      "complexity": "length",
      "complexity_weight": 0.0,
      "const_optimizer": "scipy",
      "const_params": {},
      "alpha": 0.5,
      "epsilon": 0.1,
      "verbose": true,
      "baseline": "R_e",
      "b_jumpstart": false,
      "n_cores_batch": -1,
      "summary": true,
      "debug": 0,
      "output_file": null,
      "save_all_r": false,
      "early_stopping": true,
      "hof": 100,
      "eval_all": false,
      "pareto_front": false
   },
   "controller": {
      "cell": "lstm",
      "num_layers": 1,
      "num_units": 32,
      "initializer": "zeros",
      "embedding": false,
      "embedding_size": 8,
      "optimizer": "adam",
      "learning_rate": 0.0025,
      "observe_action": false,
      "observe_parent": true,
      "observe_sibling": true,
      "entropy_weight": 0.005,
      "ppo": false,
      "ppo_clip_ratio": 0.2,
      "ppo_n_iters": 10,
      "ppo_n_mb": 4,
      "pqt": false,
      "pqt_k": 10,
      "pqt_batch_size": 1,
      "pqt_weight": 200.0,
      "pqt_use_pg": false,
      "max_length": 30,
      "off_policy_stats": true
   },
   "gp_meld": {
   		"desc_run_gp_meld" 		  	: "Turn on the GP component to iterate with RL?",
   		"run_gp_meld"             	: true,
   		"desc_init_population_size"	: "Random population to start out with other than what we get from the controller. Setting to 1 smooths init (this is a small bug). Default: 1",
        "init_population_size"    	: 1,
        "desc_p_crossover"		  	: "Probability that GP will cross bread two memebers. Note, this can co-occure independantly with mutate. Default: 0.5",
        "p_crossover"             	: 0.5,    
        "desc_p_mutate"			  	: "Probability that a member will be mutated. Note, this can co-occure independantly with crossover. Default: 0.5",
        "p_mutate"                	: 0.5,    
        "desc_seed"					: "Random seed into GP.",  
        "seed"                    	: 0,        
        "desc_verbose"			  	: "Verbosity for GP components.",
        "verbose"                 	: true,      
        "desc_max_len"			  	: "This is the max lenght of a string in GP. Most of the time, this should be the same as for RL. Default: 30",
        "max_len"                 	: 30,     
        "desc_min_len"			  	: "This is the min lenght of a string in GP. Most of the time, this should be the same as for RL. Default: 4",
        "min_len"                 	: 4,     
        "desc_steps"			  	: "How many times we run GP between each call to RL. A good numbers seemd to be from 5 to 20. Default: 20",    
        "steps"                	  	: 30,        
        "desc_rand_pop_n"		  	: "Before we run GP steps times, inject this many completely random individuals. Default: 0",
        "rand_pop_n"              	: 0,
        "desc_pop_pad"        		: "We can add actions more than once exanding GP population x many times. 0 turns this off. Default: 0",
        "pop_pad"                 	: 0,         
        "desc_fitness_metric"		: "For GP, nmse or nrmse",
        "fitness_metric"          	: "nmse",    
        "desc_recycle_max_size"  	: "If not zero, we hold over GP population from prior epochs. 1500 works well if we want to do this. Default: 0",
        "recycle_max_size"        	: 0,        
        "desc_tournament_size"		: "A larger number can converge faster, but me be more biased? Default: 3",
        "tournament_size"         	: 5,   
        "desc_max_depth"       		: "This is mainly a widget to control memory usage. Python sets a hard limit of 90. Default: 17",
        "max_depth"               	: 30,     
        "desc_train_n"    			: "How many GP observations to return with RL observations. These still get trimmed if scores are poor later on. 0 turns off return but top-1 will still be in Hall of Fame. Nate: 10",
        "train_n"                 	: 100,    
        "desc_mutate_tree_max" 		: "How deep can an inserted mutation tree be? Deeper swings more wildly. 5 is kind of crazy. Turn up with frustration?, Default: 2",
        "mutate_tree_max"         	: 3,        
        "max_const"               	: 3,
        "desc_init_const_epoch"		: "Each time we run a new epoch, init mutable/optimizable constants new?",
        "init_const_epoch"			: true,
        "constrain_const"         	: true,
        "desc_compute_priors"		: "Turn on the computation of priors for return to RL controller?",
        "compute_priors"			: true,
        "desc_parallel_eval"		: "Evaluate GP population in parallel. Overhead makes this only good for expensive tasks like Controller.",
        "parallel_eval" 			: true,
        "record_best" 				: false
   },
   "language_model_prior": {
        "saved_language_model_path": "./language_model/model/saved_model",
        "saved_language_model_lib" : "./language_model/model/saved_model/word_dict.pkl",
        "embedding_size":32, 
        "num_layers":1, 
        "num_hidden":256,
        "prob_sharing": true
    }
}
